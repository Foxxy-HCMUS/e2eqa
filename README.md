# End-to-end question-answering system

Äá»“ Ã¡n cuá»‘i kÃ¬ mÃ´n há»c thá»‘ng kÃª (statiscal learning).

## Project Organization

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ README.md          <- File README
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ processed      <- Dá»¯ liá»‡u Ä‘Ã£ qua bÆ°á»›c tiá»n xá»­ lÃ½
    â”‚Â Â  â””â”€â”€ raw            <- Dá»¯ liá»‡u thÃ´.
    â”‚
    â”œâ”€â”€ models             <- CÃ¡c checkpoint, models Ä‘Ã£ train.
    â”‚
    â”œâ”€â”€ notebooks          <- CÃ¡c file notebooks tiá»n xá»­ lÃ½ dá»¯ liá»‡u, cháº¡y láº§n lÆ°á»£t theo thá»© tá»± tá»« trÃªn xuá»‘ng.
    â”‚                         
    â”‚                         
    â”‚
    â”‚
    â”œâ”€â”€ reports            <- BÃ¡o cÃ¡o.
    â”‚Â Â  â””â”€â”€ report.pdf     
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â””â”€â”€ src                <- Source code Ä‘á»ƒ thá»±c hiá»‡n inference
    â”‚   â”‚
    â”‚ Â  â”œâ”€â”€ features       <- Scripts Ä‘á»ƒ processing dá»¯ liá»‡u
    â”‚ Â  â”‚Â Â  |â”€â”€ text_utils.py       <- CÃ¡c hÃ m Ä‘á»ƒ tiá»n xá»­ lÃ½ dá»¯ liá»‡u
    â”‚   |   â””â”€â”€ graph_utils.py      <- Tiá»n xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng graph cho qa model
    â”‚   â”‚
    â”‚ Â  â””â”€â”€ models         <- Scripts Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c models Ä‘Ã£ train Ä‘á»ƒ predict
    â”‚   â”‚   â”‚             
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_model.py     <- Inference káº¿t quáº£
    â”‚   â”‚   |â”€â”€ bm25_utils.py        <- Class BM25    
    â”‚   â”‚   |â”€â”€ pairwise_model.py    <- Class Pairwise model
    â”‚Â Â  â”‚Â Â  â””â”€â”€ qa_model.py          <- Class QA model
    â”‚   â”‚
    â”‚   â””â”€â”€ app.py         <- Streamlit app Ä‘á»ƒ cháº¡y inference
    â”‚
    â””â”€â”€ submission
        â””â”€â”€ submission.csv <- File submission

## ğŸ Demo: [https://www.youtube.com/watch?v=dDLh55HYrfg](https://www.youtube.com/watch?v=dDLh55HYrfg)

## ğŸ¤— Model: [https://huggingface.co/foxxy-hm/e2eqa-wiki](https://huggingface.co/foxxy-hm/e2eqa-wiki)

## ğŸ¤— Data: [https://huggingface.co/datasets/foxxy-hm/e2eqa-wiki](https://huggingface.co/datasets/foxxy-hm/e2eqa-wiki)

## Solution: 
#### 1. Cáº¯t dá»¯ liá»‡u thÃ nh cÃ¡c sliding windows cÃ³ kÃ­ch thÆ°á»›c 256.
#### 2. TÃ¬m cÃ¡c á»©ng viÃªn cho context vá»›i query nháº­p vÃ o báº±ng thuáº­t toÃ¡n BM25.
Äá»ƒ xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ liÃªn quan giá»¯a má»™t truy váº¥n (tÃ i liá»‡u) vá»›i má»™t tÃ i liá»‡u khÃ¡c, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ´ng thá»©c tÃ­nh BM25 nhÆ° sau:
![](image.png)
#### 3. Ranking láº¡i top cÃ¡c á»©ng viÃªn báº±ng mÃ´ hÃ¬nh BERT sentence pair
BERT sentence pair ranking lÃ  má»™t ká»¹ thuáº­t sá»­ dá»¥ng mÃ´ hÃ¬nh BERT Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a giá»¯a hai cÃ¢u, vÃ­ dá»¥ nhÆ° má»™t cÃ¢u truy váº¥n vÃ  má»™t Ä‘oáº¡n vÄƒn báº£n. Ká»¹ thuáº­t nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho nhiá»u bÃ i toÃ¡n trong truy xuáº¥t thÃ´ng tin (information retrieval) vÃ  tráº£ lá»i cÃ¢u há»i (question answering), báº±ng cÃ¡ch sá»­ dá»¥ng BERT Ä‘á»ƒ lá»c láº¡i (re-rank) cÃ¡c káº¿t quáº£ truy xuáº¥t Ä‘Æ°á»£c tá»« má»™t há»‡ thá»‘ng tÃ¬m kiáº¿m cÆ¡ báº£n. BERT sentence pair ranking cÃ³ thá»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a káº¿t quáº£ truy xuáº¥t báº±ng cÃ¡ch kháº¯c phá»¥c cÃ¡c trÆ°á»ng há»£p khÃ´ng khá»›p tá»« khÃ³a (keyword mismatch) hoáº·c sai chÃ­nh táº£ (typos) trong cÃ¢u truy váº¥n
#### 4. TÃ¬m á»©ng viÃªn cho cÃ¢u tráº£ lá»i dá»±a tá»« context Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c, dá»±a vÃ o thuáº­t toÃ¡n Louvain clustering.
#### 5. TÃ¬m cÃ¡c á»©ng viÃªn articles cho cÃ¢u tráº£ lá»i dá»±a vÃ o thuáº­t toÃ¡n BM25 vÃ  ranking láº¡i báº±ng mÃ´ hÃ¬nh BERT sentence pair khÃ¡c Ä‘á»ƒ tÃ¬m ra káº¿t quáº£ cuá»‘i cÃ¹ng. 
## Gá»“m cÃ¡c giai Ä‘oáº¡n:
### Tiá»n xá»­ lÃ½ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u
- 0.0-create-sliding-window.ipynb: Tiá»n xá»­ lÃ½ cÆ¡ báº£n (chuyá»ƒn vá» dáº¡ng viáº¿t thÆ°á»ng vÃ  loáº¡i bá» dáº¥u, loáº¡i bá» appending title), sá»­ dá»¥ng sliding window Ä‘á»ƒ cáº¯t data wiki thÃ nh cÃ¡c window kÃ­ch thÆ°á»›c 256 words: vÃ­ dá»¥: tá»« 1 máº«u data gá»“m title vÃ  text cÃ³ thá»ƒ táº¡o thÃ nh nhiá»u máº«u cá»§a cÃ¹ng title áº¥y vÃ  text khÃ¡c nhau. Tá»« Ä‘Ã³ tÄƒng cÆ°á»ng dá»¯ liá»‡u cho má»—i title vÃ  khÃ´ng bá» phÃ­ cÃ¡c text trong quÃ¡ trÃ¬nh tokenize (truncation). (wikipedia_20220620_cleaned.jsonl => wikipedia_20220620_cleaned_v2.csv)
- 0.1-find-dirty-data.ipynb: Tiá»n xá»­ lÃ½ (xoÃ¡ bá» cÃ¡c khoáº£ng tráº¯ng, dáº¥u cÃ¢u dÆ° thá»«a á»Ÿ Ä‘áº§u vÃ  cuá»‘i, tokenize,...). Lá»c ra dá»¯ liá»‡u df tá»« wikipedia_20220620_cleaned_v2.csv (cÃ³ title trong wikipedia_20220620_cleaned_v2.csv trÃ¹ng vá»›i title trong zac2022_train_merged_final.json - táº­p dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch tá»« ban tá»• chá»©c cuá»™c thi). ThÃªm trÆ°á»ng dá»¯ liá»‡u â€œdirty_textâ€ vá»›i title cá»§a zac2022_train_merged_final.json khÃ´ng náº±m trong táº­p dá»¯ liá»‡u df thÃ¬ dá»¯ liá»‡u Ä‘Ã³ lÃ  clean, ngÆ°á»£c láº¡i lÃ  dirty. (Output: zac2022_train_merged_final.json Ä‘Ã£ thÃªm trÆ°á»ng â€œdirty_textâ€)
- 0.2-create-stage1-ranking.ipynb: Chia táº­p val lÃ  má»™t pháº§n cá»§a táº­p dá»¯ liá»‡u FULL_ANNOTATION (zac2022_train_merged_final.json). ThÃªm trÆ°á»ng label cho táº­p dá»¯ liá»‡u train, nhÃ£n 1 náº¿u lÃ  FULL_ANNOTATION hoáº·c IS_LONG_ANSWER. TrÆ°á»ng text lÃ  text ban Ä‘áº§u hoáº·c dirty_text (náº¿u cÃ³).
(zac2022_train_merged_final.json => train_stage1_ranking.csv)
- 0.3-create-stage2-ranking.ipynb: Sá»­ dá»¥ng thuáº­t toÃ¡n BM25 Ä‘á»ƒ ranking cho cÃ¡c title, tá»« Ä‘Ã³ tÃ­nh topk title cho má»—i query (sá»­ dá»¥ng trÆ°á»ng short_candidate nhÆ° cÃ¡c cÃ¢u query), náº¿u topk cá»§a query chÆ°a cÃ³ true_id thÃ¬ thÃªm true_id cá»§a cÃ¢u tráº£ lá»i vÃ o. Cuá»‘i cÃ¹ng, thÃªm trÆ°á»ng â€œlabelâ€ vá»›i nhÃ£n 1 cho cÃ¢u tráº£ lá»i Ä‘Ãºng vÃ  nhÃ£n 0 cho cÃ¢u tráº£ lá»i sai, trÆ°á»ng â€œgroupâ€ Ä‘á»ƒ Ä‘Ã¡nh dáº¥u cÃ¡c á»©ng viÃªn cá»§a 1 query (má»—i group chá»‰ cÃ³ 1 cÃ¢u tráº£ lá»i Ä‘Ãºng). (wikipedia_20220620_cleaned_v2.csv => train_stage2_ranking.csv).
- 0.4-find-redirects.ipynb: TÃ¬m cÃ¡c redirect trong data wikipedia dumps vÃ  update cho táº­p thá»±c thá»ƒ ban Ä‘áº§u. (OUTPUT: entities.json).
### Training 
- 1.0-train-bm25-stage1.ipynb: Tiá»n xá»­ lÃ½ (táº¡o corpus, dictionary) vÃ  train bm25 trÃªn táº­p dá»¯ liá»‡u wikipedia_20220620_cleaned_v2.csv 
- 1.1-train-bm25-stage2.ipynb: Tiá»n xá»­ lÃ½ vÃ  train bm25 cho táº­p dá»¯ liá»‡u thÃ´  wikipedia_20220620_cleaned.jsonl
- 1.2-train-pairwise-stage1.ipynb: train Pairwise model sá»­ dá»¥ng kfold validation cho táº­p dá»¯ liá»‡u train_stage1_ranking.csv
- 1.3-train-pairwise-stage2.ipynb: train Pairwise Model sá»­ dá»¥ng kfold validation cho táº­p dá»¯ liá»‡u train_stage2_ranking.csv
- 1.4-robust-qa-model.ipynb: Sá»­ dá»¥ng táº­p dá»¯ liá»‡u df_za2022_partial_anno_pseudo_label.csv, df_za_2019_pseudo_label.csv lÃ  2 táº­p dá»¯ liá»‡u Ä‘Æ°á»£c inference tá»« pre-trained model â€œnguyenvulebinh/vi-mrc-baseâ€ cho zac2022_train_merged_final.json vá»›i category PARTIAL_ANNOTATION vÃ  táº­p dá»¯ liá»‡u cá»§a cuá»™c thi nÄƒm 2019. Sau Ä‘Ã³ tiáº¿n hÃ nh tiá»n xá»­ lÃ½ cho tá»«ng táº­p dá»¯ liá»‡u: táº¡o â€œcontextâ€, â€œquestionâ€, â€œanswer_textâ€ vÃ  â€œanswer_start_idxâ€, lÆ°u láº¡i thÃ nh file qa_full_anno_train.json. TÆ°Æ¡ng tá»± cho táº­p val, ta Ä‘Æ°á»£c file qa_full_anno_valid.json. Cuá»‘i cÃ¹ng, sá»­ dá»¥ng pre-trained model vÃ  squad (stanford question and answering dataset) metric Ä‘á»ƒ train.
### Inference
- features/text_utils.py: Chá»©a cÃ¡c hÃ m tiá»n xá»­ lÃ½ dá»¯ liá»‡u
- featues/graph_utils.py: Chá»©a hÃ m find_best_cluster nháº­n 1 list cÃ¡c answer vÃ  1 best answer lÃ m Ä‘áº§u vÃ o, sá»­ dá»¥ng thuáº­t toÃ¡n Louvain clustering Ä‘á»ƒ tÃ¬m ra best cluster.
- models/bm25_utils.py: Class BM25Gensim Ä‘á»ƒ tÃ­nh score cá»§a topk candidate. Gá»“m cÃ³ 2 stage: 
- stage1: tÃ­nh topk dá»±a vÃ o query.
- stage2: tÃ­nh topk dá»±a vÃ o query vÃ  raw_answer, náº¿u raw_answer thuá»™c entity_dict thÃ¬ thÃªm id cá»§a nÃ³ vÃ o topk
- models/pairwise_model.py: Class PairwiseModel gá»“m 2 stage:
    - stage1: predict dá»±a vÃ o question vÃ  texts.
    - stage2: predict dá»±a vÃ o question, answer, titles, texts
- models/qa_model.py: Class QAEnsembleModel: duyá»‡t láº§n lÆ°á»£t qua cÃ¡c candidate context cá»§a 1 question vÃ  thá»±c hiá»‡n predict, sau Ä‘Ã³ káº¿t há»£p vá»›i hÃ m find_best_clustere Ä‘á»ƒ chá»n ra káº¿t quáº£ tá»‘t nháº¥t.
- models/predict_model.py: thá»±c hiá»‡n load cÃ¡c checkpoint vÃ  dá»¯ liá»‡u cáº§n thiáº¿t. Sau Ä‘Ã³, thá»±c hiá»‡n retrieve Ä‘á»ƒ chá»n ra top 200 title vÃ  context phÃ¹ há»£p nháº¥t vá»›i question. Tiáº¿p theo thá»±c hiá»‡n reranking báº±ng BERT sentence pair. Cuá»‘i cÃ¹ng dÃ¹ng má»™t qa model Ä‘á»ƒ tÃ¬m ra best answer tÆ°Æ¡ng á»©ng vá»›i tá»«ng stage (entities mapping).
- app.py: deploy mÃ´ hÃ¬nh lÃªn mÃ´i trÆ°á»ng web báº±ng streamlit

